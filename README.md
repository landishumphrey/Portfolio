# Portfolio
This repository serves as a portfolio for Landis Humphrey's projects, showcasing his abilities as a Data Analyst. The following projects were completed during his time at Champlain College. The details for each project are as follows:

## 1: Implementation Of Enhanced Stratified Sampling (ESS) Algorithm
Landis worked closely with one of his professors, Vikas Thammanna Gowda, assisting him in writing a research paper for submission to an academic journal. The topic of this paper closely followed that of the previous paper, in which the Enhanced Stratified Sampling algorithm was first proposed in Gowda's publication at the 2024 IEEE International Conference on Future Machine Learning and Data Science (FMLDS). ESS is a method for use in Privacy-Preserving Big Data Publishing (PPDP), where data often involves sensitive information that must be privatized for the safety of individuals while still providing information for data analysis, a tradeoff between privacy and information loss. ESS automatically identifies the optimal size and diversity within equivalence classes, producing a dataset with the best possible anonymity and utility. Landis implemented the algorithm in this project using the Python programming language and Jupyter Notebook environment. He used his acquired knowledge to continue assisting Professor Gowda with his 2025 research paper.

## 2: Diverse Facial Recognition With YOLO Algorithm
A common problem in object detection, especially facial recognition, is built-in bias inherited from the model's designer or trainer. Landis investigated whether it was in fact possible to create an unbiased facial recognition model that properly identifies all colors, ages, and sizes of faces. He used the You Only Look Once (YOLO) algorithm as the foundation for this project. The model was trained on a dataset of diverse faces, containing varying combinations of features. After training, the model was more consistent in its facial recognition, though it still made errors in detection, mostly in images with many faces or extremely dark skin. Landis used Python and Jupyter Notebook for this project.

## 3: Web Database Integration
As a part of Landis' Database Management Systems course, he created a simple database that a user could access and manipulate on the web. It mimics a school database, with information on students, courses, classrooms, and grades. Information can be added, edited, or deleted, but only if the user logs in with the ADMIN account. The database is normalized, and some tables are connected to others via foreign keys. This means that when an edit or deletion is made in one table, all connected tables containing that updated information will also be updated. There is a demo video where Landis and his partner, Thomas, walkthrough and illustrate the application's functionality. Landis used the React library to create the web user interface and SQLite for the featured integrated database (with MySQL used for earlier stages of the project).

## 4: Web Data Visualization Project: True vs. Biased
Data visualization is a powerful tool for highlighting data and the insights derived from analysis. Visualizations can be used to send a message, and sometimes, this is used dishonestly. Landis and his partner, Aiden, explored this concept by creating pairs of visualizations based on the same data sample but conveying different messages: one truthful, one biased. Many changes made to the biased visualizations were small, but made a big difference in how the data looked and, consequently, what a viewer might think after viewing them. There is a showcase video where Landis and Aiden talk through what each pair of visualizations is based on and what they're trying to convey, and how their messaging differs. The visualizations were made in R and embedded in an HTML file created with Go and Svelte.

## 5: S&P 500 Time Series Predictive Analysis
Data that exists as a time series can be used to predict future trends within itself. This is a common technique used in the stock market to forecast how a stock(s) could perform. This is the foundation of this project; Landis and Aiden conducted basic predictive analysis of the S&P 500 using data dating back to 1992. Several forecasting techniques were used, including Mean, Naive, and numerous Exponential Smoothing variations. The highest-performing predictor was the Triple Exponential Smoothing (tES) model, which displayed a positive, upward prediction line that most closely represented the overall positive trend in the observable time series. All code and images were done in R.

## 6: Multi-Class Image Classification
For this project, Landis and his team conducted multi-class image classification on a dataset of rice grain images. The grains belonged to four distinct rice types; multiple feature-extraction methods and classification algorithms were tasked with accurately classifying images in the test sample after being trained on a training sample from the original dataset. Different method-algorithm pairings were used on the images to compare the effectiveness of the classification across many different parameters and arguments. After analysis, the most accurate pairing was the Histogram of Oriented Gradients (HOG) feature extraction with Support Vector Machine (SVM) classification, with a score of 0.98 across all evaluation metrics. The team produced a report documenting their findings. All code was done in Python with the Jupyter Notebook environment.

## 7: Student Academic Performance Investigative Analysis
Landis and his partner, Eric, wanted to investigate the relationship between a student's personal factors and their academic performance. The data was in an unusable format and required considerable data cleaning; the NumPy and Pandas libraries in Python were used, with the pyplot library for visualizations. Our data analysis revealed that students with good academic behavior had higher scores, whereas students who did not use their free time for schoolwork had lower scores overall. Decision Tree and Random Forest algorithms were used for classification, but yielded modest results, suggesting that predicting human behavior without complex methods is difficult. All code and visualizations were created in Jupyter Notebook with Python.