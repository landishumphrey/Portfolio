{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3c8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b67c0d",
   "metadata": {},
   "source": [
    "# Enhanced Stratified Sampling (ESS) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de4cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the ECs back into one DataFrame. This is used to join the stratified data back together\n",
    "# to take the total length of the dataset, when needed\n",
    "def join_strats(data_strat):\n",
    "    joined_strats = pd.DataFrame()\n",
    "\n",
    "    for strat in data_strat:\n",
    "        joined_strats = pd.concat([joined_strats, strat])\n",
    "\n",
    "    return joined_strats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abe3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates fully populated equivalence classes, or ECs, based on k, the minimum number of unique elements in an EC,\n",
    "# and l, the minimum number of unique sensitive attributes, or SAs, that need to be present within each class\n",
    "def sampling(k, l, data_strat):    \n",
    "    all_data = join_strats(data_strat)\n",
    "    \n",
    "    # Creates n/k equivalence classes to be populated\n",
    "    equivalence_classes = pd.Series(data=[list() for i in range((len(all_data)//k))])\n",
    "\n",
    "    # These iterators control different parts of this function:\n",
    "    # inc - inc iterates after every EC appendage and is used in conjunction with c_index\n",
    "    # to keep track of which chunk in 'data_strat' needs to be accessed next\n",
    "    \n",
    "    # c_index - c_index utilizes modulo to cycle through each stratified data chunk, using 'inc'\n",
    "    # as the numerator and 'l'(-diversity) as the denominator, since there are only as many chunks\n",
    "    # as there are unique SA values, l.\n",
    "    \n",
    "    # index - marks the point that is going to be added next. The chunks are processed quasi-parallelly\n",
    "    # so it takes from the same point in each chunk (when applicable) before cycling to the next index.\n",
    "    # This process is assisted by 'c_index,' as it determines if index iterates, based on\n",
    "    # whether the algorithm is currently accessing the last chunk in 'data_strat,' data_strat[l-1].\n",
    "    inc = 0\n",
    "    index = 0\n",
    "    c_index = 0\n",
    "\n",
    "    for ec in equivalence_classes:\n",
    "        # Each EC has this block run k times to fill it\n",
    "        for i in range(k):\n",
    "            # Index for the current 'data_strat' chunk\n",
    "            c_index = inc % l\n",
    "            # Depending on how far in the algorithm is, some 'data_strat' chunks won't have any\n",
    "            # more values at the current 'index.' This while loop implementation prevents\n",
    "            # any index out-of-bounds instances, finding the next chunk that holds a value \n",
    "            # at the current 'index' value.\n",
    "            while index >= len(data_strat[c_index]):\n",
    "                inc = inc + 1\n",
    "                c_index = inc % l\n",
    "                if c_index == 0:\n",
    "                    index = index + 1\n",
    "\n",
    "            # Adds a record to the currently accessed EC\n",
    "            ec.append(data_strat[c_index].loc[index])\n",
    "\n",
    "            # 'data_strat' is a Series of DataFrames, with indexes 0 to (l-1)\n",
    "            # Once 'c_index' gets to l-1, 'index' iterates to prepare for\n",
    "            # the next parallel pass through 'data_strat.'\n",
    "            if c_index == (l-1):\n",
    "                index = index + 1\n",
    "\n",
    "            # Iterates so that 'c_index' updates to read the next chunk\n",
    "            inc = inc + 1\n",
    "\n",
    "    # If the number of records isn't completely divisible by the number of ECs, there will be data left unplaced.\n",
    "    # This chunk handles that; It adds one unplaced record each to the most recently appended ECs, until all\n",
    "    # data is accounted for.\n",
    "    index = index + 1\n",
    "    # Starts from the back of 'equivalence_classes', which are where the most recently populated ECs are\n",
    "    ec_index = len(equivalence_classes) - 1\n",
    "    # Determines which chunk in 'data_strat' still has values in it that need to be placed\n",
    "    max_strat_len = max([len(data_strat[i]) for i in range(len(data_strat))])\n",
    "    while(index < max_strat_len):\n",
    "        equivalence_classes[ec_index].append(data_strat[c_index].loc[index])\n",
    "        ec_index = ec_index - 1\n",
    "        index = index + 1\n",
    "        \n",
    "    # Once all equivalence classes are populated, each EC is converted into a DataFrame for easy utility\n",
    "    equivalence_classes = [pd.DataFrame(ec, columns=all_data.columns)for ec in equivalence_classes]\n",
    "    \n",
    "    return equivalence_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d88750c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates privacy loss for the set of ECs as compared to the original data\n",
    "def privacy_loss(equivalence_classes, data, sa_column, unique_SAs):\n",
    "    # variable that will contain the sum of all privacy losses per EC\n",
    "    priv_loss_sum = 0\n",
    "    # total values in the whole dataset\n",
    "    data_len = len(data)\n",
    "\n",
    "    # We utilized Proportional l-diverse Privacy Loss to represent\n",
    "    # our privacy loss metric. This compares the distribution of \n",
    "    # SA values in each EC to the distribution within the whole set\n",
    "    for ec in equivalence_classes:\n",
    "        for sa in unique_SAs:\n",
    "            # Proportion of the SA value within the EC\n",
    "            p_dist = len(ec[ec[sa_column]==sa]) / len(ec)\n",
    "            # Proportion of the SA value within the original data\n",
    "            q_dist = len(data[data[sa_column]==sa]) / data_len\n",
    "\n",
    "            # Add the absolute value of 'p_dist' minus 'q_dist' to the sum variable\n",
    "            priv_loss_sum = priv_loss_sum + (abs(p_dist-q_dist))\n",
    "\n",
    "    print(f\"Privacy Loss: {round(priv_loss_sum/len(equivalence_classes), 2)}\")\n",
    "    return round(priv_loss_sum/len(equivalence_classes), 2)\n",
    "\n",
    "# Calculates information loss for the set of ECs as compared to the original data\n",
    "def information_loss(equivalence_classes, data, qi_column):\n",
    "    # variable that will contain the sum of all information losses per EC\n",
    "    info_loss_sum = 0\n",
    "    # lower limit of the QI column in the original data\n",
    "    min_QI = data[qi_column].min()\n",
    "    # upper limit of the QI column in the original data\n",
    "    max_QI = data[qi_column].max()\n",
    "    \n",
    "    # We utilized the Generalized Loss Metric to represent our \n",
    "    # information loss. This compares the range of quasi identifiers\n",
    "    # within each EC to the range across the whole set\n",
    "    for ec in equivalence_classes:\n",
    "        info_loss_sum = info_loss_sum + (((ec[qi_column].max())-(ec[qi_column].min()))/((max_QI)-(min_QI)))\n",
    "\n",
    "    print(f\"Information Loss: {round(info_loss_sum/len(equivalence_classes), 2)}\\n\")\n",
    "    return round(info_loss_sum/len(equivalence_classes), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05af5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the head of the Enhanced Stratified Sampling algorithm\n",
    "# It performs the sampling function on the data for each k from 2 to l\n",
    "# Each pass saves the privacy and information loss metrics calculated\n",
    "# Determines which k is best in terms of loss mitigation through combined loss\n",
    "# Returns the set of ECs that should be used for publishing\n",
    "\n",
    "def ESS(data, qi_column, sa_column):\n",
    "    \n",
    "    # splitting up data into unique SA values\n",
    "    unique_SAs = data[sa_column].unique()\n",
    "    # determining total l-diversity\n",
    "    l = len(unique_SAs)\n",
    "    \n",
    "    # Creates the different groupings of the data based on the unique SA values in the data\n",
    "    data_strat = pd.Series([pd.DataFrame(data[data[sa_column] == sa]) for sa in unique_SAs])\n",
    "    data_strat = data_strat.apply(lambda x: x.sort_values(qi_column, ignore_index=True))\n",
    "    \n",
    "    # Variables that contain the loss metrics for each set of ECs\n",
    "    priv_loss = 0\n",
    "    info_loss = 0\n",
    "    # List that stores all calculated metrics for use later\n",
    "    loss_metrics = []\n",
    "    \n",
    "    for k in range(2, (l+1)):\n",
    "        # Creates equivalence classes of minimum size, k.\n",
    "        equivalence_classes = sampling(k, l, data_strat)\n",
    "        \n",
    "        print(f\"Loss metrics for {len(equivalence_classes[0])}-anonymous equivalence classes:\")\n",
    "    \n",
    "        # Calculated privacy loss for the set of ECs\n",
    "        priv_loss = privacy_loss(equivalence_classes, data, sa_column, unique_SAs)\n",
    "        \n",
    "        # Calculated information loss for the set of ECs\n",
    "        info_loss = information_loss(equivalence_classes, data, qi_column)\n",
    "\n",
    "        # List with all metrics used and calculated\n",
    "        loss_metrics_for_k = [k, priv_loss, info_loss]\n",
    "        \n",
    "        # Stores the list above to be compared to the other metric lists at the end\n",
    "        loss_metrics.append(loss_metrics_for_k)\n",
    "        \n",
    "    # Determines the combined loss values for each set of ECs of k-anonymity\n",
    "    combined_loss_metrics = [(0.5 * loss_vals[1])+(0.5 * loss_vals[2]) for loss_vals in loss_metrics]\n",
    "    # Finds the location of the k value that produced the lowest loss score\n",
    "    index_for_k_prime = combined_loss_metrics.index(min(combined_loss_metrics))\n",
    "    # Locates the value of k within the loss_metrics list\n",
    "    k_prime = loss_metrics[index_for_k_prime][0]\n",
    "    print(f\"The best k-value to generate ECs on is k={k_prime}.\")\n",
    "    # sampling is run one more time on the chosen k value to generate 'e_prime,'\n",
    "    # the set of ECs that should be used for publishing\n",
    "    e_prime = [ec.drop(columns = sa_column) for ec in sampling(k_prime, l, data_strat)]\n",
    "    \n",
    "    return e_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac4f5e",
   "metadata": {},
   "source": [
    "# Large Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ebc3b",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b6f8a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"large_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05bcbc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55500 entries, 0 to 55499\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Name                55500 non-null  object \n",
      " 1   Age                 55500 non-null  int64  \n",
      " 2   Gender              55500 non-null  object \n",
      " 3   Blood Type          55500 non-null  object \n",
      " 4   Medical Condition   55500 non-null  object \n",
      " 5   Date of Admission   55500 non-null  object \n",
      " 6   Doctor              55500 non-null  object \n",
      " 7   Hospital            55500 non-null  object \n",
      " 8   Insurance Provider  55500 non-null  object \n",
      " 9   Billing Amount      55500 non-null  float64\n",
      " 10  Room Number         55500 non-null  int64  \n",
      " 11  Admission Type      55500 non-null  object \n",
      " 12  Discharge Date      55500 non-null  object \n",
      " 13  Medication          55500 non-null  object \n",
      " 14  Test Results        55500 non-null  object \n",
      "dtypes: float64(1), int64(2), object(12)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Displays info on the details of the dataset(# of entries, present datatypes, etc.)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6442f41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# These values are either irrelevant features or explicit identifiers (EIs) that should be removed before continuing\n",
    "data.drop_duplicates('Name', inplace = True)\n",
    "\n",
    "to_drop = ['Name', 'Doctor', 'Hospital', 'Insurance Provider', 'Room Number']\n",
    "data.drop(columns = to_drop, inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737f85d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    49992.000000\n",
       "mean     25555.725277\n",
       "std      14215.988133\n",
       "min      -2008.492140\n",
       "25%      13239.403094\n",
       "50%      25541.302839\n",
       "75%      37853.996819\n",
       "max      52764.276736\n",
       "Name: Billing Amount, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical distribution of our sensitive attribute values\n",
    "data['Billing Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "062b3acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49992"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique values in the sensitive attribute (SA) column. Going to need some temporary generalization for easier processing...\n",
    "data['Billing Amount'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c494618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounds the values in 'Billing Amount' to two decimal points\n",
    "data['Billing Amount'] = data['Billing Amount'].apply(lambda x: round(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d987d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In an effort to retain the original data, data_clean will store the preprocessed data\n",
    "data_clean = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b02cfde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These masks will temporarily generalize the data for the ESS function\n",
    "billing_mask_1 = data_clean['Billing Amount'] <= 10000\n",
    "billing_mask_2 = (data_clean['Billing Amount'] > 10000) & (data_clean['Billing Amount'] <= 20000)\n",
    "billing_mask_3 = (data_clean['Billing Amount'] > 20000) & (data_clean['Billing Amount'] <= 30000)\n",
    "billing_mask_4 = (data_clean['Billing Amount'] > 30000) & (data_clean['Billing Amount'] <= 40000)\n",
    "billing_mask_5 = data_clean['Billing Amount'] > 40000\n",
    "\n",
    "billing_masks = [billing_mask_1, billing_mask_2, billing_mask_3, billing_mask_4, billing_mask_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "409f903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized values will be stored in a new column. The values start at 5000 and increase by 10000 for each grouping\n",
    "val = 5000\n",
    "\n",
    "for bm in billing_masks:\n",
    "    data_clean.loc[bm, 'New Billing Amount'] = val\n",
    "    val = val + 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9ad6143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "New Billing Amount\n",
       "45000.0    10320\n",
       "25000.0    10228\n",
       "35000.0    10143\n",
       "15000.0    10088\n",
       "5000.0      9213\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of records per grouping\n",
    "data_clean['New Billing Amount'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee24c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Blood Type</th>\n",
       "      <th>Medical Condition</th>\n",
       "      <th>Date of Admission</th>\n",
       "      <th>Billing Amount</th>\n",
       "      <th>Admission Type</th>\n",
       "      <th>Discharge Date</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Test Results</th>\n",
       "      <th>New Billing Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>B-</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>18856.28</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>Paracetamol</td>\n",
       "      <td>Normal</td>\n",
       "      <td>15000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>A+</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>33643.33</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Inconclusive</td>\n",
       "      <td>35000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>Female</td>\n",
       "      <td>A-</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>27955.10</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>2022-10-07</td>\n",
       "      <td>Aspirin</td>\n",
       "      <td>Normal</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>O+</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>37909.78</td>\n",
       "      <td>Elective</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>35000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>Female</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>14238.32</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>2022-10-09</td>\n",
       "      <td>Penicillin</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>15000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>64</td>\n",
       "      <td>Male</td>\n",
       "      <td>O+</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>24747.35</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>2022-07-09</td>\n",
       "      <td>Paracetamol</td>\n",
       "      <td>Inconclusive</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>B+</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>40657.58</td>\n",
       "      <td>Elective</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>Aspirin</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>45000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>O-</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>8441.15</td>\n",
       "      <td>Elective</td>\n",
       "      <td>2023-09-22</td>\n",
       "      <td>Aspirin</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>81</td>\n",
       "      <td>Male</td>\n",
       "      <td>B-</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>34934.28</td>\n",
       "      <td>Elective</td>\n",
       "      <td>2020-10-14</td>\n",
       "      <td>Penicillin</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>35000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>B+</td>\n",
       "      <td>Arthritis</td>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>8926.29</td>\n",
       "      <td>Elective</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>Aspirin</td>\n",
       "      <td>Inconclusive</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49992 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Gender Blood Type Medical Condition Date of Admission  \\\n",
       "0       30    Male         B-            Cancer        2024-01-31   \n",
       "1       62    Male         A+           Obesity        2019-08-20   \n",
       "2       76  Female         A-           Obesity        2022-09-22   \n",
       "3       28  Female         O+          Diabetes        2020-11-18   \n",
       "4       43  Female        AB+            Cancer        2022-09-19   \n",
       "...    ...     ...        ...               ...               ...   \n",
       "49995   64    Male         O+      Hypertension        2022-06-28   \n",
       "49996   69    Male         B+            Cancer        2020-04-04   \n",
       "49997   73    Male         O-            Cancer        2023-09-08   \n",
       "49998   81    Male         B-            Cancer        2020-10-13   \n",
       "49999   23    Male         B+         Arthritis        2022-01-26   \n",
       "\n",
       "       Billing Amount Admission Type Discharge Date   Medication  \\\n",
       "0            18856.28         Urgent     2024-02-02  Paracetamol   \n",
       "1            33643.33      Emergency     2019-08-26    Ibuprofen   \n",
       "2            27955.10      Emergency     2022-10-07      Aspirin   \n",
       "3            37909.78       Elective     2020-12-18    Ibuprofen   \n",
       "4            14238.32         Urgent     2022-10-09   Penicillin   \n",
       "...               ...            ...            ...          ...   \n",
       "49995        24747.35      Emergency     2022-07-09  Paracetamol   \n",
       "49996        40657.58       Elective     2020-04-17      Aspirin   \n",
       "49997         8441.15       Elective     2023-09-22      Aspirin   \n",
       "49998        34934.28       Elective     2020-10-14   Penicillin   \n",
       "49999         8926.29       Elective     2022-02-03      Aspirin   \n",
       "\n",
       "       Test Results  New Billing Amount  \n",
       "0            Normal             15000.0  \n",
       "1      Inconclusive             35000.0  \n",
       "2            Normal             25000.0  \n",
       "3          Abnormal             35000.0  \n",
       "4          Abnormal             15000.0  \n",
       "...             ...                 ...  \n",
       "49995  Inconclusive             25000.0  \n",
       "49996      Abnormal             45000.0  \n",
       "49997      Abnormal              5000.0  \n",
       "49998      Abnormal             35000.0  \n",
       "49999  Inconclusive              5000.0  \n",
       "\n",
       "[49992 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data after preprocessing\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef5cfad",
   "metadata": {},
   "source": [
    "## ESS on Large Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4650d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss metrics for 2-anonymous equivalence classes:\n",
      "Privacy Loss: 1.2\n",
      "Information Loss: 0.02\n",
      "\n",
      "Loss metrics for 3-anonymous equivalence classes:\n",
      "Privacy Loss: 0.8\n",
      "Information Loss: 0.03\n",
      "\n",
      "Loss metrics for 4-anonymous equivalence classes:\n",
      "Privacy Loss: 0.4\n",
      "Information Loss: 0.04\n",
      "\n",
      "Loss metrics for 5-anonymous equivalence classes:\n",
      "Privacy Loss: 0.07\n",
      "Information Loss: 0.05\n",
      "\n",
      "The best k-value to generate ECs on is k=5\n",
      "Sample equivalence class in E':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Blood Type</th>\n",
       "      <th>Medical Condition</th>\n",
       "      <th>Date of Admission</th>\n",
       "      <th>Billing Amount</th>\n",
       "      <th>Admission Type</th>\n",
       "      <th>Discharge Date</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Test Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>16563.17</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>Penicillin</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>O-</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>2019-11-18</td>\n",
       "      <td>37070.43</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>2019-11-20</td>\n",
       "      <td>Penicillin</td>\n",
       "      <td>Inconclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Female</td>\n",
       "      <td>A-</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>2019-05-14</td>\n",
       "      <td>27631.52</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>2019-05-22</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Female</td>\n",
       "      <td>A-</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>45527.27</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>2024-01-09</td>\n",
       "      <td>Lipitor</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>2494.91</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender Blood Type Medical Condition Date of Admission  Billing Amount  \\\n",
       "0   18    Male        AB+          Diabetes        2020-03-04        16563.17   \n",
       "0   18    Male         O-            Cancer        2019-11-18        37070.43   \n",
       "0   18  Female         A-           Obesity        2019-05-14        27631.52   \n",
       "0   18  Female         A-           Obesity        2023-12-31        45527.27   \n",
       "0   18    Male        AB+           Obesity        2020-04-17         2494.91   \n",
       "\n",
       "  Admission Type Discharge Date  Medication  Test Results  \n",
       "0         Urgent     2020-04-01  Penicillin      Abnormal  \n",
       "0         Urgent     2019-11-20  Penicillin  Inconclusive  \n",
       "0      Emergency     2019-05-22   Ibuprofen      Abnormal  \n",
       "0      Emergency     2024-01-09     Lipitor      Abnormal  \n",
       "0         Urgent     2020-05-01   Ibuprofen      Abnormal  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function call for ESS on the large dataset\n",
    "# e_prime is the set of ECs that should be used in publishing\n",
    "e_prime = ESS(data_clean, 'Age', 'New Billing Amount')\n",
    "print(\"Sample equivalence class in E':\")\n",
    "e_prime[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d390abf1",
   "metadata": {},
   "source": [
    "# Small Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09de425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"small_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48f118a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique values in the sensitive attribute (SA) column. Going to need some temporary generalization for easier processing...\n",
    "data['Income'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23b95b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These masks will temporarily generalize the data for the ESS function. There is a skewed distribution\n",
    "# so two sets of masks are made based on low and high income.\n",
    "low_income_mask_1 = data['Income'] <= 66000\n",
    "low_income_mask_2 = (data['Income'] > 66000) & (data['Income'] <= 69000)\n",
    "low_income_mask_3 = (data['Income'] > 69000) & (data['Income'] <= 72000)\n",
    "low_income_mask_4 = (data['Income'] > 72000) & (data['Income'] <= 75000)\n",
    "\n",
    "low_income_masks = [low_income_mask_1, low_income_mask_2, low_income_mask_3, low_income_mask_4]\n",
    "\n",
    "high_income_mask_1 = (data['Income'] > 75000) & (data['Income'] <= 875000)\n",
    "high_income_mask_2 = (data['Income'] > 875000) & (data['Income'] <= 1675000)\n",
    "high_income_mask_3 = (data['Income'] > 1675000) & (data['Income'] <= 2475000)\n",
    "high_income_mask_4 = data['Income'] > 2475000\n",
    "\n",
    "high_income_masks = [high_income_mask_1, high_income_mask_2, high_income_mask_3, high_income_mask_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "793f869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized values will be stored in a new column. The values start at 66000/875000 and increase by 3000/800000 \n",
    "# for each grouping, depending on whether they are low- or high-income masks, respectively.\n",
    "val = 66000\n",
    "\n",
    "for im in low_income_masks:\n",
    "    data.loc[im, 'New Income Amount'] = val\n",
    "    val = val + 3000\n",
    "    \n",
    "val = 875000\n",
    "\n",
    "for im in high_income_masks:\n",
    "    data.loc[im, 'New Income Amount'] = val\n",
    "    val = val + 800000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387db63",
   "metadata": {},
   "source": [
    "## ESS On Small Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa277291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss metrics for 2-anonymous equivalence classes:\n",
      "Privacy Loss: 1.4\n",
      "Information Loss: 0.14\n",
      "\n",
      "Loss metrics for 3-anonymous equivalence classes:\n",
      "Privacy Loss: 1.11\n",
      "Information Loss: 0.18\n",
      "\n",
      "Loss metrics for 4-anonymous equivalence classes:\n",
      "Privacy Loss: 0.82\n",
      "Information Loss: 0.26\n",
      "\n",
      "Loss metrics for 5-anonymous equivalence classes:\n",
      "Privacy Loss: 0.61\n",
      "Information Loss: 0.29\n",
      "\n",
      "Loss metrics for 6-anonymous equivalence classes:\n",
      "Privacy Loss: 0.45\n",
      "Information Loss: 0.31\n",
      "\n",
      "Loss metrics for 7-anonymous equivalence classes:\n",
      "Privacy Loss: 0.49\n",
      "Information Loss: 0.34\n",
      "\n",
      "Loss metrics for 8-anonymous equivalence classes:\n",
      "Privacy Loss: 0.49\n",
      "Information Loss: 0.34\n",
      "\n",
      "The best k-value to generate ECs on is k=6\n",
      "Sample equivalence class in E':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Number_of_Dependents</th>\n",
       "      <th>Location</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Employment_Status</th>\n",
       "      <th>Household_Size</th>\n",
       "      <th>Homeownership_Status</th>\n",
       "      <th>Type_of_Housing</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Primary_Mode_of_Transportation</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>Urban</td>\n",
       "      <td>14</td>\n",
       "      <td>Married</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>1</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Female</td>\n",
       "      <td>Biking</td>\n",
       "      <td>74840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>High School</td>\n",
       "      <td>Education</td>\n",
       "      <td>2</td>\n",
       "      <td>Rural</td>\n",
       "      <td>28</td>\n",
       "      <td>Single</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>3</td>\n",
       "      <td>Own</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Male</td>\n",
       "      <td>Public transit</td>\n",
       "      <td>528755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>High School</td>\n",
       "      <td>Others</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>17</td>\n",
       "      <td>Single</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1</td>\n",
       "      <td>Own</td>\n",
       "      <td>Single-family home</td>\n",
       "      <td>Male</td>\n",
       "      <td>Public transit</td>\n",
       "      <td>71674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>Rural</td>\n",
       "      <td>48</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>2</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Female</td>\n",
       "      <td>Biking</td>\n",
       "      <td>3165470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>High School</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>2</td>\n",
       "      <td>Urban</td>\n",
       "      <td>47</td>\n",
       "      <td>Married</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>2</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Female</td>\n",
       "      <td>Walking</td>\n",
       "      <td>67192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Technology</td>\n",
       "      <td>5</td>\n",
       "      <td>Rural</td>\n",
       "      <td>16</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>6</td>\n",
       "      <td>Own</td>\n",
       "      <td>Single-family home</td>\n",
       "      <td>Male</td>\n",
       "      <td>Car</td>\n",
       "      <td>56924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Education_Level  Occupation  Number_of_Dependents Location  \\\n",
       "0   18        Master's  Healthcare                     5    Urban   \n",
       "0   18     High School   Education                     2    Rural   \n",
       "0   18     High School      Others                     0    Urban   \n",
       "0   18        Master's  Healthcare                     5    Rural   \n",
       "0   18     High School  Healthcare                     2    Urban   \n",
       "0   18       Doctorate  Technology                     5    Rural   \n",
       "\n",
       "   Work_Experience Marital_Status Employment_Status  Household_Size  \\\n",
       "0               14        Married         Part-time               1   \n",
       "0               28         Single     Self-employed               3   \n",
       "0               17         Single         Full-time               1   \n",
       "0               48        Married     Self-employed               2   \n",
       "0               47        Married         Part-time               2   \n",
       "0               16        Married     Self-employed               6   \n",
       "\n",
       "  Homeownership_Status     Type_of_Housing  Gender  \\\n",
       "0                 Rent           Apartment  Female   \n",
       "0                  Own           Apartment    Male   \n",
       "0                  Own  Single-family home    Male   \n",
       "0                 Rent           Apartment  Female   \n",
       "0                 Rent           Apartment  Female   \n",
       "0                  Own  Single-family home    Male   \n",
       "\n",
       "  Primary_Mode_of_Transportation   Income  \n",
       "0                         Biking    74840  \n",
       "0                 Public transit   528755  \n",
       "0                 Public transit    71674  \n",
       "0                         Biking  3165470  \n",
       "0                        Walking    67192  \n",
       "0                            Car    56924  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function call for ESS on the small dataset\n",
    "# e_prime is the set of ECs that should be used in publishing\n",
    "e_prime = ESS(data, 'Age', 'New Income Amount')\n",
    "print(\"Sample equivalence class in E':\")\n",
    "e_prime[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
